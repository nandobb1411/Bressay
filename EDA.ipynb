{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN to extract the features of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN to interpret the sequential data extracted by CNNs, LSTM (Long Short-Term Memory) units are often used due to their efficiency in handling sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTC Loss To handle the alignment between input sequences (the image features) and the target sequences (the transcribed text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'bressay-competition\\bressay\\sets\\test.txt', 'r') as file:\n",
    "    test_content = file.readlines()\n",
    "\n",
    "with open(r'bressay-competition\\bressay\\sets\\training.txt', 'r') as file:\n",
    "    training_content = file.readlines()\n",
    "\n",
    "with open(r'bressay-competition\\bressay\\sets\\validation.txt', 'r') as file:\n",
    "    validation_content = file.readlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter_rasura = 0\n",
    "# if \"--xxx---\" in data_text:\n",
    "#     counter_rasura += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting line dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_directory = r'bressay-competition\\bressay\\data\\lines'\n",
    "test = {}\n",
    "train = {}\n",
    "val = {}\n",
    "\n",
    "def count_unique_characters(*data_structures):\n",
    "    unique_characters = set()\n",
    "\n",
    "    for data_structure in data_structures:\n",
    "        for data in data_structure.values():\n",
    "            if 'txt' in data:\n",
    "                for text_entry in data['txt']:\n",
    "                    unique_characters.update(text_entry)\n",
    "\n",
    "    sorted_characters = sorted(unique_characters)\n",
    "    characters_string = ''.join(sorted_characters)\n",
    "    return characters_string\n",
    "\n",
    "\n",
    "def find_max_text_length(*data_structures):\n",
    "    max_length = 0\n",
    "    for data_structure in data_structures:\n",
    "        len_line = 0\n",
    "        for data in data_structure.values():\n",
    "            if 'txt' in data:\n",
    "                for line in data[\"txt\"]:\n",
    "                    if len(line) > len_line:\n",
    "                        len_line = len(line)\n",
    "                if len_line > max_length:\n",
    "                    max_length = len_line\n",
    "\n",
    "    return max_length\n",
    "\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape\n",
    "    \n",
    "    final_img = np.ones([64, 256])*255 # blank white image\n",
    "    \n",
    "    # crop\n",
    "    if w > 256:\n",
    "        img = img[:, :256]\n",
    "        \n",
    "    if h > 64:\n",
    "        img = img[:64, :]\n",
    "    \n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "def collect_file_data_to_dataframe(dir_name, base_path):\n",
    "    data = []\n",
    "    full_path = os.path.join(base_path, dir_name)\n",
    "    \n",
    "    if os.path.isdir(full_path):\n",
    "        for file in os.listdir(full_path):\n",
    "            if file.endswith('.png'):\n",
    "                img_file_path = os.path.join(full_path, file)\n",
    "                txt_file_name = file.replace('.png', '.txt')\n",
    "                txt_file_path = os.path.join(full_path, txt_file_name)\n",
    "                \n",
    "                if os.path.exists(txt_file_path):\n",
    "                    with open(txt_file_path, 'r', encoding='utf-8') as txt_file:\n",
    "                        identity = txt_file.read()\n",
    "                        data.append([img_file_path, identity])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=['FILENAME', 'IDENTITY'])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs = []\n",
    "training_dfs = []\n",
    "val_dfs = []\n",
    "\n",
    "for dir_name in test_content:\n",
    "    dir_name = dir_name.strip()\n",
    "    test_dfs.append(collect_file_data_to_dataframe(dir_name, lines_directory))\n",
    "\n",
    "for dir_name in training_content:\n",
    "    dir_name = dir_name.strip()\n",
    "    training_dfs.append(collect_file_data_to_dataframe(dir_name, lines_directory))\n",
    "\n",
    "# for dir_name in val_content:\n",
    "#     dir_name = dir_name.strip()\n",
    "#     val_dfs.append(collect_file_data_to_dataframe(dir_name, lines_directory))\n",
    "\n",
    "# Concatenate all DataFrames in the lists\n",
    "test = pd.concat(test_dfs, ignore_index=True)\n",
    "train = pd.concat(training_dfs, ignore_index=True)\n",
    "# val_df = pd.concat(val_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 19628\n",
    "test_size = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for i in range(train_size):\n",
    "    \n",
    "    relative_path = train.loc[i, 'FILENAME'].replace('\\\\\\\\', '\\\\')\n",
    "    img_dir = fr\"{relative_path}\"\n",
    "\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is not None:\n",
    "        image = preprocess(image)\n",
    "        image = image / 255.0  # Normalize\n",
    "        train_x.append(image)\n",
    "    else:\n",
    "        print(f\"Image not found or unable to load: {img_dir}\")\n",
    "\n",
    "train_x = np.array(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for i in range(test_size):\n",
    "    \n",
    "    relative_path = test.loc[i, 'FILENAME'].replace('\\\\\\\\', '\\\\')\n",
    "    img_dir = fr\"{relative_path}\"\n",
    "\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is not None:\n",
    "        image = preprocess(image)\n",
    "        image = image / 255.0  # Normalize\n",
    "        test_x.append(image)\n",
    "    else:\n",
    "        print(f\"Image not found or unable to load: {img_dir}\")\n",
    "\n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
    "test_x = np.array(test_x).reshape(-1, 256, 64, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing txt (preparing for CTC loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    special_token_mappings = {\n",
    "        '--text--': '=',\n",
    "        '--xxx--': '+',\n",
    "        '##text##': '*',\n",
    "        '$$text$$': '^',\n",
    "        '@@???@@': '&',\n",
    "        '##--xxx--##': '%',\n",
    "        '$$--xxx--$$': '`',\n",
    "        '##@@???@@##': '{',\n",
    "        '$$@@???@@$$': '}'\n",
    "    }\n",
    "    for token, unique_char in special_token_mappings.items():\n",
    "        text = text.replace(token, unique_char)\n",
    "    return text\n",
    "\n",
    "train['IDENTITY'] = train['IDENTITY'].apply(preprocess_text)\n",
    "test['IDENTITY'] = test['IDENTITY'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Ao longo do desenvolvimento de sociedades comp...\n",
       "1        zes de explicar e intervir positivamente no fu...\n",
       "2        a psiquiatria --real-- surgiram para tratar e ...\n",
       "3        na sociedade brasileira, a manutenção de um es...\n",
       "4        causada por uma questão histórica e por uma fa...\n",
       "                               ...                        \n",
       "19623    pulação e o ambiente cinematográfico, através ...\n",
       "19624    se utilizam de espaços públicos, como escolas ...\n",
       "19625    em cartaz nos cinemas, a fim de proporcionar à...\n",
       "19626    democrático + e permitir que esses indivíduos ...\n",
       "19627     ra crítica por meio dos & metragens em exibição.\n",
       "Name: IDENTITY, Length: 19628, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['IDENTITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = ' =+^&*!\"%`\\'(),}-.{/0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\\\\]`abcdefghijklmnopqrstuvwxyz|ª°´ºÀÁÈÉÍÓÚàáâãçèéêíóôõúü'\n",
    "max_str_len = 250\n",
    "num_of_characters = len(alphabets) + 1\n",
    "num_of_timestamps = 64\n",
    "\n",
    "\n",
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        \n",
    "    return np.array(label_num)\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ra crítica por meio dos & metragens em exibição \n",
      " [ 79  62   0  64  79 108  81  70  64  62   0  77  76  79   0  74  66  70\n",
      "  76   0  65  76  80   0   4   0  74  66  81  79  62  68  66  75  80   0\n",
      "  66  74   0  66  85  70  63  70 104 103  76]\n"
     ]
    }
   ],
   "source": [
    "name = 'ra crítica por meio dos & metragens em exibição'\n",
    "print(name, '\\n',label_to_num(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19628"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.ones([train_size, max_str_len]) * -1\n",
    "train_label_len = np.zeros([train_size, 1])\n",
    "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
    "train_output = np.zeros([train_size])\n",
    "\n",
    "for i in range(train_size):\n",
    "    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n",
    "    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.ones([test_size, max_str_len]) * -1\n",
    "test_label_len = np.zeros([test_size, 1])\n",
    "test_input_len = np.ones([test_size, 1]) * (num_of_timestamps-2)\n",
    "test_output = np.zeros([test_size])\n",
    "\n",
    "for i in range(test_size):\n",
    "    test_label_len[i] = len(test.loc[i, 'IDENTITY'])\n",
    "    test_y[i, 0:len(test.loc[i, 'IDENTITY'])]= label_to_num(test.loc[i, 'IDENTITY'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILENAME</th>\n",
       "      <th>IDENTITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\0651-04...</td>\n",
       "      <td>Ao longo do desenvolvimento de sociedades comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\0651-04...</td>\n",
       "      <td>zes de explicar e intervir positivamente no fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\0651-04...</td>\n",
       "      <td>a psiquiatria --real-- surgiram para tratar e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\0651-04...</td>\n",
       "      <td>na sociedade brasileira, a manutenção de um es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\0651-04...</td>\n",
       "      <td>causada por uma questão histórica e por uma fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19623</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\4775-02...</td>\n",
       "      <td>pulação e o ambiente cinematográfico, através ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19624</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\4775-02...</td>\n",
       "      <td>se utilizam de espaços públicos, como escolas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19625</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\4775-02...</td>\n",
       "      <td>em cartaz nos cinemas, a fim de proporcionar à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19626</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\4775-02...</td>\n",
       "      <td>democrático + e permitir que esses indivíduos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19627</th>\n",
       "      <td>bressay-competition\\bressay\\data\\lines\\4775-02...</td>\n",
       "      <td>ra crítica por meio dos &amp; metragens em exibição.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19628 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                FILENAME  \\\n",
       "0      bressay-competition\\bressay\\data\\lines\\0651-04...   \n",
       "1      bressay-competition\\bressay\\data\\lines\\0651-04...   \n",
       "2      bressay-competition\\bressay\\data\\lines\\0651-04...   \n",
       "3      bressay-competition\\bressay\\data\\lines\\0651-04...   \n",
       "4      bressay-competition\\bressay\\data\\lines\\0651-04...   \n",
       "...                                                  ...   \n",
       "19623  bressay-competition\\bressay\\data\\lines\\4775-02...   \n",
       "19624  bressay-competition\\bressay\\data\\lines\\4775-02...   \n",
       "19625  bressay-competition\\bressay\\data\\lines\\4775-02...   \n",
       "19626  bressay-competition\\bressay\\data\\lines\\4775-02...   \n",
       "19627  bressay-competition\\bressay\\data\\lines\\4775-02...   \n",
       "\n",
       "                                                IDENTITY  \n",
       "0      Ao longo do desenvolvimento de sociedades comp...  \n",
       "1      zes de explicar e intervir positivamente no fu...  \n",
       "2      a psiquiatria --real-- surgiram para tratar e ...  \n",
       "3      na sociedade brasileira, a manutenção de um es...  \n",
       "4      causada por uma questão histórica e por uma fa...  \n",
       "...                                                  ...  \n",
       "19623  pulação e o ambiente cinematográfico, através ...  \n",
       "19624  se utilizam de espaços públicos, como escolas ...  \n",
       "19625  em cartaz nos cinemas, a fim de proporcionar à...  \n",
       "19626  democrático + e permitir que esses indivíduos ...  \n",
       "19627   ra crítica por meio dos & metragens em exibição.  \n",
       "\n",
       "[19628 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label :  plo, foi responsável por retratar essa falsa felicidade das famílias tradicionais estaduni- \n",
      "train_y :  [ 77.  73.  76.  13.   0.  67.  76.  70.   0.  79.  66.  80.  77.  76.\n",
      "  75.  80. 101.  83.  66.  73.   0.  77.  76.  79.   0.  79.  66.  81.\n",
      "  79.  62.  81.  62.  79.   0.  66.  80.  80.  62.   0.  67.  62.  73.\n",
      "  80.  62.   0.  67.  66.  73.  70.  64.  70.  65.  62.  65.  66.   0.\n",
      "  65.  62.  80.   0.  67.  62.  74. 108.  73.  70.  62.  80.   0.  81.\n",
      "  79.  62.  65.  70.  64.  70.  76.  75.  62.  70.  80.   0.  66.  80.\n",
      "  81.  62.  65.  82.  75.  70.  15.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.] \n",
      "train_label_len :  [91.] \n",
      "train_input_len :  [62.]\n"
     ]
    }
   ],
   "source": [
    "print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n",
    "      '\\ntrain_input_len : ', train_input_len[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label :  ciado às doenças mentais e, por isso, uma resolução urge. \n",
      "train_y :  [ 64.  70.  62.  65.  76.   0. 100.  80.   0.  65.  76.  66.  75. 104.\n",
      "  62.  80.   0.  74.  66.  75.  81.  62.  70.  80.   0.  66.  13.   0.\n",
      "  77.  76.  79.   0.  70.  80.  80.  76.  13.   0.  82.  74.  62.   0.\n",
      "  79.  66.  80.  76.  73.  82. 104. 103.  76.   0.  82.  79.  68.  66.\n",
      "  16.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.\n",
      "  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.] \n",
      "train_label_len :  [57.] \n",
      "train_input_len :  [62.]\n"
     ]
    }
   ],
   "source": [
    "print('True label : ',test.loc[10, 'IDENTITY'] , '\\ntrain_y : ',test_y[10],'\\ntrain_label_len : ',test_label_len[10], \n",
    "      '\\ntrain_input_len : ', test_input_len[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 256, 64, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 256, 64, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 256, 64, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 256, 64, 32)       0         \n",
      "                                                                 \n",
      " max1 (MaxPooling2D)         (None, 128, 32, 32)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 128, 32, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 128, 32, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 128, 32, 64)       0         \n",
      "                                                                 \n",
      " max2 (MaxPooling2D)         (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 64, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 64, 16, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 64, 16, 128)       0         \n",
      "                                                                 \n",
      " max3 (MaxPooling2D)         (None, 64, 8, 128)        0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64, 8, 128)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 1024)          0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64, 64)            65600     \n",
      "                                                                 \n",
      " lstm1 (Bidirectional)       (None, 64, 512)           657408    \n",
      "                                                                 \n",
      " lstm2 (Bidirectional)       (None, 64, 512)           1574912   \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 64, 115)           58995     \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 64, 115)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2450483 (9.35 MB)\n",
      "Trainable params: 2450035 (9.35 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# CNN to RNN\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINNNN!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node model_7/ctc/CTCLoss defined at (most recent call last):\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\Samsung\\AppData\\Local\\Temp\\ipykernel_12896\\3621477213.py\", line 3, in <module>\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py\", line 212, in call\n\n  File \"C:\\Users\\Samsung\\AppData\\Local\\Temp\\ipykernel_12896\\3353683713.py\", line 6, in ctc_lambda_func\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\backend.py\", line 7171, in ctc_batch_cost\n\nAll labels must be nonnegative integers, batch: 0 labels: 77,66,75,80,62,79,0,64,76,75,80,64,70,66,75,81,66,0,15,15,88,64,76,74,76,88,15,15,0,-1,-1,66,-1,-1,0,73,66,83,66,74,0,77,62,79,62,0,62,0,64,76,74,82,75,70,65,62,65,66,0,62,0,79,66,67,73,66,85,103,76,0,80,76,63,79,66,0,76,0,81,66,74,62,13,0,79,66,65,82,87,70,75,65,76,0,76,0,77,79,66,64,76,75,64,66,70,81,76,16,0,96\n\t [[{{node model_7/ctc/CTCLoss}}]] [Op:__inference_train_function_55457]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_final\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mctc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred: y_pred}, optimizer\u001b[38;5;241m=\u001b[39mAdam(lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_input_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_input_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node model_7/ctc/CTCLoss defined at (most recent call last):\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\Samsung\\AppData\\Local\\Temp\\ipykernel_12896\\3621477213.py\", line 3, in <module>\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py\", line 212, in call\n\n  File \"C:\\Users\\Samsung\\AppData\\Local\\Temp\\ipykernel_12896\\3353683713.py\", line 6, in ctc_lambda_func\n\n  File \"c:\\Users\\Samsung\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\src\\backend.py\", line 7171, in ctc_batch_cost\n\nAll labels must be nonnegative integers, batch: 0 labels: 77,66,75,80,62,79,0,64,76,75,80,64,70,66,75,81,66,0,15,15,88,64,76,74,76,88,15,15,0,-1,-1,66,-1,-1,0,73,66,83,66,74,0,77,62,79,62,0,62,0,64,76,74,82,75,70,65,62,65,66,0,62,0,79,66,67,73,66,85,103,76,0,80,76,63,79,66,0,76,0,81,66,74,62,13,0,79,66,65,82,87,70,75,65,76,0,76,0,77,79,66,64,76,75,64,66,70,81,76,16,0,96\n\t [[{{node model_7/ctc/CTCLoss}}]] [Op:__inference_train_function_55457]"
     ]
    }
   ],
   "source": [
    "model_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n",
    "\n",
    "model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output, \n",
    "                validation_data=([test_x, test_y, test_input_len, test_label_len], test_output),\n",
    "                epochs=60, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
